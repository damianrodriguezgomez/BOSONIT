{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0- TITANIC\n",
    "###### Damián Rodríguez Gómez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EL proyecto de Titanic, está compuesto por 2 bases de datos, y el objetivo principal es: \"Predecir la supervivenvia del Titanic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Índice\n",
    "\n",
    "###### 1-Importar librerias.\n",
    "###### 2-Entender los datos.\n",
    "###### 3-Preprocesamiento de los datos.\n",
    "###### 4-Aplicación de algoritmos de Machine Learning.\n",
    "###### 5-Predicción utilizando los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variables del proyecto: \n",
    "\n",
    "- Passengerld: Id único del pasajero.\n",
    "- Survived: Supeviviente {0:NO, 1:SI}.\n",
    "- Pclass: Clase de Billete.\n",
    "- Name: Nombres.\n",
    "- Sex: Género.\n",
    "- Age: Edad.\n",
    "- SibSp: Cónyuges a bordo.\n",
    "- Parch: Nº de Pais.\n",
    "- Ticket: Nº del billete.\n",
    "- Fare: Tarifa de los pasajeros.\n",
    "- Cabin: Nº de Cabina.\n",
    "- Embarked: Puerto de Embarcación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Importamos todas las librerias necesarias\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 Importamos los datos y los intentamos entender:\n",
    "\n",
    "df_train=pd.read_csv('./train.csv')\n",
    "df_test=pd.read_csv('./test.csv')\n",
    "\n",
    "print(df_train.head())\n",
    "print(' ')\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de datos:\n",
      "(891, 12)\n",
      "(418, 11)\n"
     ]
    }
   ],
   "source": [
    "#2.2 Vamos a verificar la cantidad de datos que hay en el dataset.\n",
    "\n",
    "print('Cantidad de datos:')\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de datos:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#2.3 Verifico el tipo de datos contenidos en ambos dataset.\n",
    "\n",
    "print('Tipos de datos:')\n",
    "print(df_train.info())\n",
    "print(df_test.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos faltantes:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#2.4 Verifico los datos faltantes del dataset.\n",
    "print('Datos faltantes:')\n",
    "print(pd.isnull(df_train).sum())\n",
    "print(pd.isnull(df_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadística del Dataset:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
      "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
      "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
      "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
      "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
      "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
      "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
      "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
      "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "#2.4 Verifico las estadísticas del Dataset.\n",
    "\n",
    "print('Estadística del Dataset:')\n",
    "print(df_train.describe())\n",
    "print(df_test.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1 Cambio los datos de 'Sexo' en números:\n",
    "\n",
    "df_train['Sex'].replace(['female','male'],[0,1],inplace=True)\n",
    "df_test['Sex'].replace(['female','male'],[0,1],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2 Cambio los datos de 'Embarque' en números:\n",
    "df_train['Embarked'].replace(['Q','S','C'],[0,1,2],inplace=True)\n",
    "df_test['Embarked'].replace(['Q','S','C'],[0,1,2],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.758888888888887\n",
      "30.216507177033492\n"
     ]
    }
   ],
   "source": [
    "#3.3 Reemplazo los datos faltantes en la edad por la media de esta columna:\n",
    "print(df_train['Age'].mean())\n",
    "print(df_test['Age'].mean())\n",
    "promedio=30\n",
    "df_train['Age'] = df_train['Age'].replace(np.nan, promedio)\n",
    "df_test['Age'] = df_test['Age'].replace(np.nan, promedio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.4 Creo varios grupos de acuerdo a bandas de las edades:\n",
    "#3.4.1 Bandas:0-8, 9-15, 16-18, 19-25, 26-40, 41-60, 61-100\n",
    "bins = [0, 8, 15, 18, 25, 40, 60, 100]\n",
    "names = ['1', '2', '3', '4', '5', '6', '7']\n",
    "df_train['Age'] = pd.cut(df_train['Age'], bins, labels = names)\n",
    "df_test['Age'] = pd.cut(df_test['Age'], bins, labels = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.5 Se elimina la columna de 'Cabin' ya que tiene muchos datos perdidos\n",
    "df_train.drop(['Cabin'], axis = 1, inplace=True)\n",
    "df_test.drop(['Cabin'], axis = 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.6 ELimino las columnas que considero que no son necesarias para el análisis. \n",
    "df_train = df_train.drop(['PassengerId','Name','Ticket'], axis=1)\n",
    "df_test = df_test.drop(['Name','Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.6 Elimino las filas con los datos perdidos:\n",
    "df_train.dropna(axis=0, how='any', inplace=True)\n",
    "df_test.dropna(axis=0, how='any', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos faltantes:\n",
      "Survived    0\n",
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "PassengerId    0\n",
      "Pclass         0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n",
      "Cantidad de datos:\n",
      "(889, 8)\n",
      "(417, 8)\n",
      "Head\n",
      "   Survived  Pclass  Sex Age  SibSp  Parch     Fare  Embarked\n",
      "0         0       3    1   4      1      0   7.2500       1.0\n",
      "1         1       1    0   5      1      0  71.2833       2.0\n",
      "2         1       3    0   5      0      0   7.9250       1.0\n",
      "3         1       1    0   5      1      0  53.1000       1.0\n",
      "4         0       3    1   5      0      0   8.0500       1.0\n",
      " \n",
      "   PassengerId  Pclass  Sex Age  SibSp  Parch     Fare  Embarked\n",
      "0          892       3    1   5      0      0   7.8292         0\n",
      "1          893       3    0   6      1      0   7.0000         1\n",
      "2          894       2    1   7      0      0   9.6875         0\n",
      "3          895       3    1   5      0      0   8.6625         1\n",
      "4          896       3    0   4      1      1  12.2875         1\n"
     ]
    }
   ],
   "source": [
    "#3.7 Verifico los datos, que esten correctos:\n",
    "print('Datos faltantes:')\n",
    "print(pd.isnull(df_train).sum())\n",
    "print(pd.isnull(df_test).sum())\n",
    "print('Cantidad de datos:')\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print('Head')\n",
    "print(df_train.head())\n",
    "print(' ')\n",
    "print(df_test.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.1 Separo la columna con la información de los sobrevivientes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2 Separo los datos 'train' en entrenamiento y prueba para probar algoritmos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.3 Regresión Logística:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.4 Support Vector Machines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.5 K neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7a72b34bacb54ed7877af4c7ddc120a9ffb6d7a04be730abeda9f34c261cdef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
